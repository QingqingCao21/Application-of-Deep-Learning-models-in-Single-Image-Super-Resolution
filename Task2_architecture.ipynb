{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep SRCNN (residual blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import DIV2K\n",
    "train = DIV2K(scale=4, downgrade='bicubic', subset='train')\n",
    "train_ds = train.dataset(batch_size=16, random_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline srcnn\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Conv2D, Input, Lambda, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
    "\n",
    "def srcnn_res6():\n",
    "    '''\n",
    "    creates a srcnn model with residual blocks\n",
    "    '''\n",
    "    x_in = Input(shape=(None, None, 3))\n",
    "    x = (x_in - DIV2K_RGB_MEAN) / 127.5 # normalize\n",
    "    \n",
    "    x = Conv2D(64 * (2 ** 2), 3, padding='same')(x) # pre-upsampling\n",
    "    x = tf.nn.depth_to_space(x, 2) \n",
    "    x = Conv2D(64 * (2 ** 2), 3, padding='same')(x)\n",
    "    x = tf.nn.depth_to_space(x, 2)   \n",
    "    \n",
    "    b = Conv2D(64,3,padding = 'same', activation='relu')(x)\n",
    "    x = b\n",
    "    \n",
    "    for i in range(6):\n",
    "        x_b = Conv2D(64, 3, padding='same', activation='relu')(b)\n",
    "        x_b = Conv2D(64, 3, padding='same', activation='relu')(x_b)\n",
    "        b = Add()([x_b, b])        \n",
    "    \n",
    "    x = Add()([x, b])\n",
    "    \n",
    "    x = Conv2D(3, 3, padding='same')(x)\n",
    "    \n",
    "    x = x * 127.5 + DIV2K_RGB_MEAN # denormalize\n",
    "    return Model(x_in, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res6 = srcnn_res6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2/100 [..............................] - ETA: 12s - loss: 6237.9072WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0420s vs `on_train_batch_end` time: 0.1070s). Check your callbacks.\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 1146.4373\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 344.6303\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 265.0926\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 246.6658\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 232.9064\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "# Adam optimizer with a scheduler that halfs learning rate after 20,000 steps\n",
    "optim_srcnn = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[20000], values=[1e-4, 5e-5]))\n",
    "\n",
    "# Compile and train model for 300,000 steps with L1 pixel loss\n",
    "model_res6.compile(optimizer=optim_srcnn, loss='mean_squared_error')\n",
    "history_res6 = model_res6.fit(train_ds, epochs=50, steps_per_epoch=1000)\n",
    "\n",
    "# Save model weights\n",
    "weights_dir = 'weights/'\n",
    "model_res6.save_weights(os.path.join(weights_dir, 'weights-srcnn-res6-mse-x4.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep SRCNN (inception block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import DIV2K\n",
    "train = DIV2K(scale=4, downgrade='bicubic', subset='train')\n",
    "train_ds = train.dataset(batch_size=16, random_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline srcnn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Conv2D, Input, Lambda, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "DIV2K_RGB_MEAN = np.array([0.4488, 0.4371, 0.4040]) * 255\n",
    "\n",
    "def srcnn_incep3():\n",
    "    '''\n",
    "    creates a srcnn model with residual blocks\n",
    "    '''\n",
    "    x_in = Input(shape=(None, None, 3))\n",
    "    x = (x_in - DIV2K_RGB_MEAN) / 127.5 # normalize\n",
    "    \n",
    "    x = Conv2D(64 * (2 ** 2), 3, padding='same')(x) # pre-upsampling\n",
    "    x = tf.nn.depth_to_space(x, 2) \n",
    "    x = Conv2D(64 * (2 ** 2), 3, padding='same')(x)\n",
    "    x = tf.nn.depth_to_space(x, 2)   \n",
    "    \n",
    "    for i in range(3):\n",
    "        x1 = Conv2D(16, 1, padding='same', activation='relu')(x)\n",
    "        x2 = Conv2D(16, 3, padding='same', activation='relu')(x)\n",
    "        x3 = Conv2D(16, 5, padding='same', activation='relu')(x)\n",
    "        x4 = Conv2D(16, 9, padding='same', activation='relu')(x)\n",
    "        x = Concatenate(axis = -1)([x1,x2,x3,x4])\n",
    "        \n",
    "    x = Conv2D(3, 5, padding='same')(x)\n",
    "    \n",
    "    x = x * 127.5 + DIV2K_RGB_MEAN # denormalize\n",
    "    return Model(x_in, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_incep3 = srcnn_incep3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 41s 415ms/step - loss: 1662.8253\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 568.1018\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 41s 411ms/step - loss: 385.2892\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 35s 353ms/step - loss: 316.6289\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 41s 410ms/step - loss: 281.8763\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "# Adam optimizer with a scheduler that halfs learning rate after 20,000 steps\n",
    "optim_srcnn = Adam(learning_rate=PiecewiseConstantDecay(boundaries=[20000], values=[1e-4, 5e-5]))\n",
    "\n",
    "# Compile and train model for 300,000 steps with L1 pixel loss\n",
    "model_incep3.compile(optimizer=optim_srcnn, loss='mean_squared_error')\n",
    "history_incep3 = model_incep3.fit(train_ds, epochs=50, steps_per_epoch=1000)\n",
    "\n",
    "# Save model weights\n",
    "weights_dir = 'weights/'\n",
    "model_incep3.save_weights(os.path.join(weights_dir, 'weights-srcnn-incep3-mse-x4.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "article.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.639px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
